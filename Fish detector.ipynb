{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of ML assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcMgtG6TZJ-E",
        "colab_type": "code",
        "outputId": "86a3db29-116d-4836-f758-b537bb9d6618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!mkdir -p /content/data/\n",
        "!wget --no-check-certificate \\\n",
        "  https://www.dropbox.com/s/e2xya1pzr2tm9xr/QUT_fish_data.zip\\\n",
        "  -O /content/data/QUT_fish_data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-13 07:58:01--  https://www.dropbox.com/s/e2xya1pzr2tm9xr/QUT_fish_data.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/e2xya1pzr2tm9xr/QUT_fish_data.zip [following]\n",
            "--2019-11-13 07:58:01--  https://www.dropbox.com/s/raw/e2xya1pzr2tm9xr/QUT_fish_data.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc5b2d9c4fe2bb637882bf1aa8f9.dl.dropboxusercontent.com/cd/0/inline/AsRYH794ySnZRRv_nloWKD7QDm_rWII23ycO8kXpXE3y5SgZZC3eojk8dZq5K1OeNh4vGrO5Ui7TTslCTdUU1xQUniqpEmzja2NDcSDFOtkFWA/file# [following]\n",
            "--2019-11-13 07:58:02--  https://uc5b2d9c4fe2bb637882bf1aa8f9.dl.dropboxusercontent.com/cd/0/inline/AsRYH794ySnZRRv_nloWKD7QDm_rWII23ycO8kXpXE3y5SgZZC3eojk8dZq5K1OeNh4vGrO5Ui7TTslCTdUU1xQUniqpEmzja2NDcSDFOtkFWA/file\n",
            "Resolving uc5b2d9c4fe2bb637882bf1aa8f9.dl.dropboxusercontent.com (uc5b2d9c4fe2bb637882bf1aa8f9.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uc5b2d9c4fe2bb637882bf1aa8f9.dl.dropboxusercontent.com (uc5b2d9c4fe2bb637882bf1aa8f9.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AsS7rYJz6VN_ISVeFAzeP9ktR1NILZaTnFq0rS7DT_ZXTvM_x4BMXeo3Shgh0PtGENnM9bDf53zlSFtVsOzZOPamcxny7nHJPQqSfMb_wzdN--5YI6Yu0RV41tBCxEKVev26OgfuZ8pDCqgEcfxCREuqRbC7Qxgqq6so0zV1EITyR9JMZNklUKt69FW6XhC2XUxw8HExvoke5ZATaUdVgh41gG8GD6NB7spunJ5EHmLumpD1AeH-jFb_A_qgrQRVPI71_rty4ykztDPc0wxGx5WsPdh8lHxbuilP6JQTY3kZkE9kaMqiC38ijsMJ7KBuVMTAvcwhT0gmAO9X0br9R_XX/file [following]\n",
            "--2019-11-13 07:58:02--  https://uc5b2d9c4fe2bb637882bf1aa8f9.dl.dropboxusercontent.com/cd/0/inline2/AsS7rYJz6VN_ISVeFAzeP9ktR1NILZaTnFq0rS7DT_ZXTvM_x4BMXeo3Shgh0PtGENnM9bDf53zlSFtVsOzZOPamcxny7nHJPQqSfMb_wzdN--5YI6Yu0RV41tBCxEKVev26OgfuZ8pDCqgEcfxCREuqRbC7Qxgqq6so0zV1EITyR9JMZNklUKt69FW6XhC2XUxw8HExvoke5ZATaUdVgh41gG8GD6NB7spunJ5EHmLumpD1AeH-jFb_A_qgrQRVPI71_rty4ykztDPc0wxGx5WsPdh8lHxbuilP6JQTY3kZkE9kaMqiC38ijsMJ7KBuVMTAvcwhT0gmAO9X0br9R_XX/file\n",
            "Reusing existing connection to uc5b2d9c4fe2bb637882bf1aa8f9.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1411537902 (1.3G) [application/zip]\n",
            "Saving to: ‘/content/data/QUT_fish_data.zip’\n",
            "\n",
            "/content/data/QUT_f 100%[===================>]   1.31G  48.4MB/s    in 29s     \n",
            "\n",
            "2019-11-13 07:58:32 (46.1 MB/s) - ‘/content/data/QUT_fish_data.zip’ saved [1411537902/1411537902]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzg3KfJkoFcQ",
        "colab_type": "code",
        "outputId": "e8fd38d7-b899-43b2-833b-17dcc47b1803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://www.dropbox.com/s/p2a4rwv9x8cf78a/not_fish_data.zip?dl= \\\n",
        "  -O /content/data/not_fish_data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-13 07:59:03--  https://www.dropbox.com/s/p2a4rwv9x8cf78a/not_fish_data.zip?dl=\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/p2a4rwv9x8cf78a/not_fish_data.zip [following]\n",
            "--2019-11-13 07:59:03--  https://www.dropbox.com/s/raw/p2a4rwv9x8cf78a/not_fish_data.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc8b60d3aafb34c2d7f6250ac768.dl.dropboxusercontent.com/cd/0/inline/AsRd32A3E1K6Ijl3YrwuLJ3N3X6dO4gHZrgOfoG4OyvRgNS5BfJHvcgNIyBCHpd9ZTEWTouMQi5C0hAiCAUzF8F_UtFAFxj3CRAaPMF4ehwZG9g6RToJjR666WQ4NajWTrc/file# [following]\n",
            "--2019-11-13 07:59:04--  https://uc8b60d3aafb34c2d7f6250ac768.dl.dropboxusercontent.com/cd/0/inline/AsRd32A3E1K6Ijl3YrwuLJ3N3X6dO4gHZrgOfoG4OyvRgNS5BfJHvcgNIyBCHpd9ZTEWTouMQi5C0hAiCAUzF8F_UtFAFxj3CRAaPMF4ehwZG9g6RToJjR666WQ4NajWTrc/file\n",
            "Resolving uc8b60d3aafb34c2d7f6250ac768.dl.dropboxusercontent.com (uc8b60d3aafb34c2d7f6250ac768.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uc8b60d3aafb34c2d7f6250ac768.dl.dropboxusercontent.com (uc8b60d3aafb34c2d7f6250ac768.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AsT3Fmcx0mhyRiPan8MLmSBpClIZJvQ4k5UxTkJvq3kmcU-J9ONC7xucQghAg_7ZE064fnOmO-2hhQLSn9l8I9_7fexBXVBxEUG6mJ4IZaSLo9ncHxAehxlfesHF5VWytjLYV3NcTUwMaVa9aYbM8j6ESMuHEWxTfbMhc_Jw9dkIXXeh1VCRr9HUMvwtPO-PLjPu6Edfl20u8HPWIQGIb84p2Lez7r1VexD6C71TXkLyRpC30u6p0wBF03OEIZu6pfDvOJWiFUzSMQejzv_WV1Tox2XiaZ9Ww0vt6zGLB1zlrC7NU2NSgMfhylDIlgDNalMjSZ_KEDh4nO2TKBtJVoikg9S80VlMq-WVBG9t59p1Ew/file [following]\n",
            "--2019-11-13 07:59:04--  https://uc8b60d3aafb34c2d7f6250ac768.dl.dropboxusercontent.com/cd/0/inline2/AsT3Fmcx0mhyRiPan8MLmSBpClIZJvQ4k5UxTkJvq3kmcU-J9ONC7xucQghAg_7ZE064fnOmO-2hhQLSn9l8I9_7fexBXVBxEUG6mJ4IZaSLo9ncHxAehxlfesHF5VWytjLYV3NcTUwMaVa9aYbM8j6ESMuHEWxTfbMhc_Jw9dkIXXeh1VCRr9HUMvwtPO-PLjPu6Edfl20u8HPWIQGIb84p2Lez7r1VexD6C71TXkLyRpC30u6p0wBF03OEIZu6pfDvOJWiFUzSMQejzv_WV1Tox2XiaZ9Ww0vt6zGLB1zlrC7NU2NSgMfhylDIlgDNalMjSZ_KEDh4nO2TKBtJVoikg9S80VlMq-WVBG9t59p1Ew/file\n",
            "Reusing existing connection to uc8b60d3aafb34c2d7f6250ac768.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43840702 (42M) [application/zip]\n",
            "Saving to: ‘/content/data/not_fish_data.zip’\n",
            "\n",
            "/content/data/not_f 100%[===================>]  41.81M  30.5MB/s    in 1.4s    \n",
            "\n",
            "2019-11-13 07:59:06 (30.5 MB/s) - ‘/content/data/not_fish_data.zip’ saved [43840702/43840702]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0GUdLG4FnIa",
        "colab_type": "code",
        "outputId": "52d9947f-4349-4351-a5f9-7c444f7bd98e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E__v__ysvdTU",
        "colab_type": "code",
        "outputId": "9aef04de-e8b4-4f56-b398-060ad82bf881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import random\n",
        "from shutil import copyfile\n",
        "\n",
        "local_zip = '/content/data/QUT_fish_data.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/data/')\n",
        "zip_ref.close()\n",
        "\n",
        "try:\n",
        "    os.mkdir('/content/data/images')\n",
        "    os.mkdir('/content/data/images/training')\n",
        "    os.mkdir('/content/data/images/testing')\n",
        "    os.mkdir('/content/data/images/training/pos')\n",
        "    os.mkdir('/content/data/images/testing/pos')\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    files = []\n",
        "    for filename in os.listdir(SOURCE):\n",
        "        file = SOURCE + filename\n",
        "        if os.path.getsize(file) > 0:\n",
        "            files.append(filename)\n",
        "        else:\n",
        "            print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "    training_length = int(len(files) * SPLIT_SIZE)\n",
        "    testing_length = int(len(files) - training_length)\n",
        "    shuffled_set = random.sample(files, len(files))\n",
        "    training_set = shuffled_set[0:training_length]\n",
        "    testing_set = shuffled_set[-testing_length:]\n",
        "\n",
        "    for filename in training_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TRAINING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "    for filename in testing_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TESTING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "\n",
        "FISH_SOURCE_DIR = \"/content/data/QUT_fish_data/images/raw_images/\"\n",
        "TRAINING_FISH_DIR = \"/content/data/images/training/pos/\"\n",
        "TESTING_FISH_DIR = \"/content/data/images/testing/pos/\"\n",
        "\n",
        "split_size = .7\n",
        "split_data(FISH_SOURCE_DIR, TRAINING_FISH_DIR, TESTING_FISH_DIR, split_size)\n",
        "\n",
        "print(len(os.listdir('/content/data/images/training/pos/')))\n",
        "print(len(os.listdir('/content/data/images/testing/pos/')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3084\n",
            "1322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzjsKUTNHkQw",
        "colab_type": "code",
        "outputId": "e89e07ef-feee-49f7-d50f-e8cc49f3e998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "local_zip = '/content/data/not_fish_data.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/data/')\n",
        "zip_ref.close()\n",
        "\n",
        "try:\n",
        "    os.mkdir('/content/data/images/training/neg')\n",
        "    os.mkdir('/content/data/images/testing/neg')\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "NoFISH_SOURCE_DIR = \"/content/data/not_fish/\"\n",
        "TRAINING_NoFISH_DIR = \"/content/data/images/training/neg/\"\n",
        "TESTING_NoFISH_DIR = \"/content/data/images/testing/neg/\"\n",
        "\n",
        "split_size = .7\n",
        "split_data(NoFISH_SOURCE_DIR, TRAINING_NoFISH_DIR, TESTING_NoFISH_DIR, split_size)\n",
        "\n",
        "print(len(os.listdir('/content/data/images/training/neg/')))\n",
        "print(len(os.listdir('/content/data/images/testing/neg/')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2795\n",
            "1198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWVwfwiJIDYI",
        "colab_type": "code",
        "outputId": "c87a9735-cba8-4a21-e443-ec3150941412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "base_model = tf.keras.applications.resnet_v2.ResNet50V2(include_top=False, weights='imagenet', input_shape=(256,256,3), pooling=None )\n",
        "\n",
        "\n",
        "'''for layer in base_model.layers:\n",
        "      layer.trainable = False'''\n",
        "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)\n",
        "model = Model(base_model.input, x)\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 64, 64, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 64, 64, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 64, 64, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 64, 64, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 64, 64, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 32, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 32, 32, 256)  0           max_pooling2d[0][0]              \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 32, 32, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 32, 32, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 32, 32, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 512)  0           conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 16, 16, 512)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 16, 16, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 16, 16, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 1024)   0           conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 8, 8, 1024)   0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 8, 8, 1024)   4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 8, 8, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 8, 8, 2048)   8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 8, 8, 2048)   0           post_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           post_relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         2098176     global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 25,664,001\n",
            "Trainable params: 25,618,561\n",
            "Non-trainable params: 45,440\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42w2rX2nL_al",
        "colab_type": "code",
        "outputId": "d8ea7aab-86fb-4be0-a195-a9e8a1ead101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=180,\n",
        "      width_shift_range=0.3,\n",
        "      height_shift_range=0.3,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=-0.2,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/data/images/training/',  # This is the source directory for training images\n",
        "        target_size=(256, 256),  # All images will be resized to 256x256\n",
        "        batch_size=28,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/data/images/testing',  # This is the source directory for training images\n",
        "        target_size=(256, 256),  # All images will be resized to 256x256\n",
        "        batch_size=24,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5878 images belonging to 2 classes.\n",
            "Found 2520 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MToARslrbTZ",
        "colab_type": "code",
        "outputId": "190da0f1-235c-4fbb-b850-2f1b719f3a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "      \n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 10,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Epoch 1/10\n",
            "100/100 - 107s - loss: 0.0521 - acc: 0.9786 - val_loss: 0.6087 - val_acc: 0.8925\n",
            "Epoch 2/10\n",
            "Epoch 1/10\n",
            "100/100 - 86s - loss: 0.0610 - acc: 0.9843 - val_loss: 0.0222 - val_acc: 0.9967\n",
            "Epoch 3/10\n",
            "Epoch 1/10\n",
            "100/100 - 87s - loss: 0.0361 - acc: 0.9911 - val_loss: 0.3094 - val_acc: 0.9642\n",
            "Epoch 4/10\n",
            "Epoch 1/10\n",
            "100/100 - 87s - loss: 0.0266 - acc: 0.9904 - val_loss: 0.0271 - val_acc: 0.9958\n",
            "Epoch 5/10\n",
            "Epoch 1/10\n",
            "100/100 - 88s - loss: 0.0250 - acc: 0.9914 - val_loss: 0.0163 - val_acc: 0.9942\n",
            "Epoch 6/10\n",
            "Epoch 1/10\n",
            "100/100 - 87s - loss: 0.0255 - acc: 0.9925 - val_loss: 0.0319 - val_acc: 0.9967\n",
            "Epoch 7/10\n",
            "Epoch 1/10\n",
            "100/100 - 87s - loss: 0.0281 - acc: 0.9929 - val_loss: 0.1733 - val_acc: 0.9783\n",
            "Epoch 8/10\n",
            "Epoch 1/10\n",
            "100/100 - 87s - loss: 0.0427 - acc: 0.9911 - val_loss: 0.9520 - val_acc: 0.9758\n",
            "Epoch 9/10\n",
            "Epoch 1/10\n",
            "100/100 - 88s - loss: 0.0354 - acc: 0.9911 - val_loss: 0.0657 - val_acc: 0.9925\n",
            "Epoch 10/10\n",
            "Epoch 1/10\n",
            "100/100 - 87s - loss: 0.0243 - acc: 0.9939 - val_loss: 0.1967 - val_acc: 0.9708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbG5GccsXgMM",
        "colab_type": "code",
        "outputId": "bdd6f197-9a63-425e-9667-c87856fadd8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3hUVfrA8e8LIfTeRECKKBBKECJg\no4mKq8IComJBsbDrirrYuyyuugq66uq6NhBcBbFhr4A/RNdCMZCEXpTQe28J7++PcydMQsokmclN\nZt7P88yTmVvfuZl577nnnHtGVBVjjDHRq5zfARhjjIksS/TGGBPlLNEbY0yUs0RvjDFRzhK9McZE\nOUv0xhgT5SzRxyARKS8ie0TkhHAu6ycRaSUiYe8rLCJ9RWR10OslInJWKMsWYV+vish9RV3fmLzE\n+R2AKZiI7Al6WQU4CGR6r/+kqm8WZnuqmglUC/eysUBVW4djOyJyPXClqvYK2vb14di2MTlZoi8D\nVDUr0XolxutV9Zu8lheROFXNKInYjCmIfR79Z1U3UUBE/i4ib4vIZBHZDVwpIqeJyI8iskNE1ovI\ncyJSwVs+TkRURJp7r//rzf9cRHaLyP9EpEVhl/Xmny8iS0Vkp4j8S0S+F5Fr8og7lBj/JCLLRWS7\niDwXtG55EfmniGwVkZVAv3yOz/0iMiXHtBdE5Gnv+fUissh7Pyu80nZe20oXkV7e8yoi8oYXWyrQ\nJceyD4jISm+7qSLS35veAXgeOMurFtsSdGxHB63/Z++9bxWRaSLSKJRjU5jjHIhHRL4RkW0iskFE\n7graz4PeMdklInNE5PjcqslEZHbg/+wdz1nefrYBD4jISSIy09vHFu+41Qxav5n3Hjd7858VkUpe\nzG2DlmskIvtEpG5e79fkQlXtUYYewGqgb45pfwcOARfhTt6VgVOBbrirtpbAUmCkt3wcoEBz7/V/\ngS1AElABeBv4bxGWbQDsBgZ4824DDgPX5PFeQonxQ6Am0BzYFnjvwEggFWgC1AVmuY9zrvtpCewB\nqgZtexOQ5L2+yFtGgD7AfqCjN68vsDpoW+lAL+/5OOBboDbQDEjLsewlQCPvf3K5F0NDb971wLc5\n4vwvMNp7fq4XYyegEvBvYEYox6aQx7kmsBG4FagI1AC6evPuBZKBk7z30AmoA7TKeayB2YH/s/fe\nMoAbgfK4z+PJwNlAvPc5+R4YF/R+UrzjWdVb/gxv3svAo0H7uR34wO/vYVl7+B6APQr5D8s70c8o\nYL07gHe857kl7/8ELdsfSCnCstcC3wXNE2A9eST6EGPsHjT/feAO7/ksXBVWYN4fciafHNv+Ebjc\ne34+sCSfZT8BbvKe55fofw/+XwB/CV42l+2mABd4zwtK9BOBx4Lm1cC1yzQp6NgU8jhfBfySx3Ir\nAvHmmB5Kol9ZQAwXB/YLnAVsAMrnstwZwCpAvNe/AoPC/b2K9odV3USPNcEvRKSNiHzqXYrvAsYA\n9fJZf0PQ833k3wCb17LHB8eh7puZntdGQowxpH0Bv+UTL8BbwFDv+eXe60AcF4rIT161wg5caTq/\nYxXQKL8YROQaEUn2qh92AG1C3C6495e1PVXdBWwHGgctE9L/rIDj3BSX0HOT37yC5Pw8HiciU0Vk\nrRfD6zliWK2u4T8bVf0ed3Vwpoi0B04APi1iTDHLEn30yNm18CVcCbKVqtYAHsKVsCNpPa7ECYCI\nCNkTU07FiXE9LkEEFNT9cyrQV0Qa46qW3vJirAy8CzyOq1apBXwVYhwb8opBRFoCL+KqL+p6210c\ntN2CuoKuw1UHBbZXHVdFtDaEuHLK7zivAU7MY7285u31YqoSNO24HMvkfH9P4HqLdfBiuCZHDM1E\npHwecUwCrsRdfUxV1YN5LGfyYIk+elUHdgJ7vcasP5XAPj8BOovIRSISh6v3rR+hGKcCfxWRxl7D\n3N35LayqG3DVC6/jqm2WebMq4uqNNwOZInIhri451BjuE5Fa4u4zGBk0rxou2W3GnfNuwJXoAzYC\nTYIbRXOYDFwnIh1FpCLuRPSdquZ5hZSP/I7zR8AJIjJSRCqKSA0R6erNexX4u4icKE4nEamDO8Ft\nwDX6lxeREQSdlPKJYS+wU0Sa4qqPAv4HbAUeE9fAXVlEzgia/wauqudyXNI3hWSJPnrdDlyNaxx9\nCddoGlGquhG4FHga98U9EZiPK8mFO8YXgenAQuAXXKm8IG/h6tyzqm1UdQcwCvgA16B5Me6EFYqH\ncVcWq4HPCUpCqroA+Bfws7dMa+CnoHW/BpYBG0UkuAomsP4XuCqWD7z1TwCuCDGunPI8zqq6EzgH\nGIw7+SwFenqzxwLTcMd5F65htJJXJXcDcB+uYb5VjveWm4eBrrgTzkfAe0ExZAAXAm1xpfvfcf+H\nwPzVuP/zQVX9oZDv3XC0gcOYsPMuxdcBF6vqd37HY8ouEZmEa+Ad7XcsZZHdMGXCSkT64Xq47Md1\nzzuMK9UaUyRee8cAoIPfsZRVVnVjwu1MYCWubvo8YKA1npmiEpHHcX35H1PV3/2Op6yyqhtjjIly\nVqI3xpgoV+rq6OvVq6fNmzf3OwxjjClT5s6du0VVc+3OXGCiF5HxuK5Pm1S1fS7zBXgWdwv6Ptxt\n0PO8eVcDD3iL/l1VJxa0v+bNmzNnzpyCFjPGGBNERPK8OzyUqpvXyWdkQNy4ISd5jxG4/s14N1Y8\njBtMqSvwsIjUDi1kY4wx4VJgolfVWbgbSfIyAJikzo9ALW841fOAr1V1m6pux90gkt8JwxhjTASE\nozG2MdkHMEr3puU1/RgiMsIb63rO5s2bwxCSMcaYgFLR60ZVX1bVJFVNql8/v6FRjDHGFFY4Ev1a\nso/g18Sbltd0Y4wxJSgcif4jYJg3ul13YKeqrge+BM4VkdpeI+y53jRjjDElKJTulZOBXkA9EUnH\n9aSpAKCq/wE+w3WtXI7rXjncm7dNRB7BjSwIMEZV82vUNcYYEwEFJnpVHVrAfAVuymPeeGB80UIr\nmw4ehNdfh6uvhkqV/I7GlAY7dsCKFbB8OaxZAwMHwol5/dSHMRFQ6u6MLes+/RT+/GfYsgXuv9/v\naExJUIWtW10iDzwCiX35cvdZCDZuHMyaBSef7E+8JvZYog+zlBT394kn4IYboEEDf+Px25gx8PLL\n0LAhHHdc3o+GDaF6dZBI/9hhEanCxo3Zk3nwY+fOo8uKQNOm0KoVDBrk/gYeGRnQrx/06QP/939W\nsjclwxJ9mKWkQJ067os/Zgw8/7zfEfln6VJ45BHo1Mmd8DZsgORklzAzMo5dvnLl/E8GwSeFihXD\nH++RI7B2bd4l8717jy5bvjw0b+6Sd/fu2ZN58+b5V9tNnw69erlkP2sWNCvoR/iMKaZSN0xxUlKS\nluWxbhIS3CX58cfDK69AamrsXqIPHAjffAPLlrkEHXDkCGzb5hJ/QY+tW3Pfdu3aoZ0U6tZ1STkg\nI8PVk+dWKl+xwrWxBMTHQ8uWRxP4iScefd6sGVTI69deQzB/vkv0deq4kn2TJgWvY0x+RGSuqibl\nOs8SffgcPAhVq8Ldd8Mtt7iEcO658N57Ba8bbb79Fnr3hkcfhfvuK/p2Dh2CTZuyJ/+NG3M/KezZ\nc+z65ctD/fou6e/bB6tWweHDR+dXrpw9gQc/mjTJfpIIt59/hr59oVEjd7waNYrcvkwpt3UrpKW5\nkkjv3kXaRH6J3qpuwmjpUsjMhPbtXfXCXXfBQw/BDz/A6af7HV3JOXIEbrvN1VOPGlW8bcXHu4Qb\nSol3z568TwIbNrjqlMGDsyfzRo38axfo2hW++MIVBvr2dcnebgyPYqqQng6LFh37CAz90rkzzJ0b\n9l1bog+jQENse28w59tug3//G+64A77/vvQ2NIbbG2+4qok333Ql5pJSrZp7lKUGztNPdz21zj/f\nJfsZM1x1U8hUXeni8GH3OHTo6PP8pmVmQr16ro6xfn0oVypGQ4kOGRmwcmXuCT34srN2bVfXO2AA\ntG3rHgkJEQnJEn0YpaRAXBy0bu1eV63qGmRHjIAPPnA9MKLd3r2uqqZrV7jsMr+jKUGqrm5o5073\n2LHj6POcrw8cyJaEex4+zEft23Hh3NGc13wV37S9mVq6veBkHZhWXHFxrm6rUSOX+AOPnK/r1o3K\nE8L//ueq0W65pZCFsf373WV8IImnpbm/y5a5/01A48YuiQ8ffjSht23reiiUUOnPEn0YpaS4htf4\n+KPThg+HZ56Be+6Biy4qXgNeWTBuHKxbB1OnlrGccOhQ9mScX6LO63luXYmClSsHNWu6y5wKFY4+\n4uPpW2Ed7598kD8u+QfnL32Gr7o+SPXKGdmWybZObtNCWSYwTcR18F+3zj3Wr3d/V66E2bNzbwWP\ni8ue/PM6MdStW2YuXz/5BC6+2LWv7d/vvqfH2LkzeyIPPFatcid4cP/bli1dAr/ggqOl8zZtoEaN\nEn1PubHG2DA68UTo0sUluWCffOKS/PPPw0253kMcHdaudSe6Cy449hhE1JEjsGtX9sSb19+8nh84\nUPB+qleHWrVcsq5ZM7Tnwa+rVi0wAU6bBkOGuC6bX3zhVvHFwYOuYSNwIgg+GQS/3pbLqCbx8S7p\nF3SFULu2ryeEt95yd7B36gTNminvvw8fjlnARbVnZ0/o69cfXaliRfchDyTyQOn8pJN8vxXeet2U\ngL17XR4YPdo1wAZTdQ3paWmuG19ET/BHjrhWvQkTXMmsYkWXLapUcY/A89ym5fU857SKFXP9gg4f\n7r48ixa5wk3IDhwILUnv2JH7tN27j5as8lKp0tGEW9hkXauW++dGsgtOkHfecdVevXq5QkJJtnMU\n2oEDR08AuZ0IAs937Dh23YoVXftACR3XYC/uvpKbto2hZ8Wf+LDBDcTt2kaPnR+xhNb8SHfa1UjP\nXs0SeLRo4Uu8obBeNyVg0SKXa9of86u6LieOHevqrceOdTcRhd1vv8HEiS7Br17tEtR557l5+/a5\nM9HOne7Lt3evmxaYnplZuH2JHHMCmEdnJqZN5I6W79Py7rezz4f8E3hw5/XcBKo8ghNwy5bZXxf0\nN7g+rZQbMsTVJF11lbsXYdo03wuLeatUySW/Fi3yX27fPvfZy3ky2Ly54JN0GKnCP1Iu4L7fhnBR\nk/m83XM8leOSoGpVpjVcwKnPdqB/9WR+nlOeuvXKRvVTKKxEHyavv+5KtEuW5H2D1NCh8OGHrq2m\nca6/tVVI+/e7Vt4JE9ztlqpw9tlw7bUuQ4RSFFR1DXqBpB/8N6/nOabp3n30+fZBUnY3Y1m7gdQ6\ntCn7sqqhJ+Tc/larVmbqfMNp/Hi47jq48EJ3L0YZOleVSqquDv7JJ+Hyy913Nmeb2Y8/uiup006D\nr74qW21q+ZXoUdVS9ejSpYuWRbffrlqxompGRt7LrFypWqGC6nXXFWNHR46o/vyz6o03qtasqQqq\nzZurjh6tumpVMTZcdNOmuTBeeMGX3Ue1F190x3bQINVDh/yOpuzKyFAdMcIdy7/8RTUzM+9lJ006\nulxZAszRPPKq74k956OsJvrzzlPt1Kng5UaNUi1XTnXhwkLuYNMm1aefVm3f3v3bKlVSveIK1enT\n8//URtjBg6qtWqm2bat6+LBvYUS1Z55x//LLLsu/IGFyd/Cg6qWXumN4332urFSQO+90y7/4YuTj\nCxdL9CWgSRPVK68seLktW1xB/A9/CGGjhw+rfvSR6sCBqnFx7t/Vtavqf/6jun17sWMOh3/+04X1\n2Wd+RxLdnnjCHeerr/b1vF7m7N2rev757tg9+WTo62VkuO9oXJzqzJkRCy+sLNFH2Pbt7kj+4x+h\nLf/kk2756dPzWGDRItW77lI97ji3YP36rm4oJSVsMYfD1q2qtWurnntuaKUkUzxjxriPww03WLIP\nxY4dqmeeqSqi+vLLRVu/TRvVunVVV6wIf3zhZok+wmbPdkfyk09CW37/ftUTTlDt3DnoC7tzp+or\nr6iedprbWPnyqv37uwrwUlo5e+utrhpqwQK/I4kd99/vPh433WQn1/xs2qR6yimuTeztt4u+naVL\nXWGmfXvVXbvCF18kWKKPsP/8xx3J1atDX+eNN9w6bz6QpjpsmGqVKm5C27aqY8eqrl8fuYDDYMkS\nd1k7YoTfkcSWI0dU77jDfVRuu82SfW5+/121dWvVypVVP/+8+Nv7+mtX7howoHRfSVmij7CRI1Wr\nVSvEl+733zXzb49op/gUbcYqPVCtrsuYP/5YZr65Awa497xhg9+RxJ4jR1Rvvtl9e++9t8x8ZErE\nkiXuarlGDdXvvgvfdp97zh3v++8P3zbDzRJ9hPXurdqtWwEL7d+vOmWKq9AWUQX9OvF2BdVxjx0s\nkTjDZcYM98l57DG/I4ldR44c7S44erTf0ZQO8+erNmjgmrTmzQvvto8cUb3+ene8J08O77bDxRJ9\nhNWvn0ff+CNHVOfOdRWqtWu7w920qepDD2W17vTrp1qrlmvYLAsyMlw30hNOUN23z+9oYltmpuo1\n17iP1eOP+x2Nv2bPdr3ZmjZVXbw4Mvs4eNA17laqpDpnTmT2URyW6CNo40Z3FP/5z6CJmze7zs8d\nO7qZFSuqDh2q+tVXx3SETk52Bfw77ijZuItqwgT3lt56y+9IjKr7OF1+ufufPP2039H444svXH38\nySer/vZbZPe1caMr5DRurLpuXWT3VViW6CNo+nR3FL+aus314erXzzX1g2pSkuq//626bVu+2xg+\nXDU+3rcbW0O2Z49qo0aumsrqhUuPw4dVL75YY/Lu5HfecV+3Tp1cEi4Jv/6qWrWq+x7s318y+wyF\nJfpI+e03fXbgTAXVdTRyh7NlS1c8T04OeTNr1hy90bU0e/hh9xa//97vSExOhw653rjgeunGgtde\nc917zzij5O8ffO89d6yvuqr0FHos0YfTokWuFTIpSRV0BP/ROuW365GHHnbJvYj/9Xvvdf+NuXPD\nG264pKe7y+NLLvE7EpOXAwfcBaWI6sSJfkcTWU895b4v553nrjT98Le/uRjGjvVn/zlZoi+OQIPq\n/fe7Pu5uEDx33fbEE3p6533ao0fxd7Njh2q9eqp9+pSeEkKwq692TQ2lvXop1u3bp3r22a6kO2WK\n39GE35Ejqg884L6CQ4a4BlI/YxkyxJ1YP/3UvzgCLNEXVkaG64Q7apRqs2buMJUr5/pR/utfrq5F\n3T+6Ro3wjXIX6Ktb2saNmTPHxXX33X5HYkKxZ4/qWWe5m3zee8/vaMInM9PdswKul1tpGOBtzx7X\nPlCjhmpamr+xWKIPxcGDql9+qfqnP6k2bOgOTXy86oUXqo4f73rS5PD77xrWBrDASJDt25eOD7Gq\nO5n17Om6kO7Y4Xc0JlS7drnRNCpUUP34Y7+jKb7Dh92ggeCGfSpNV72//eb677dqVWC/i4gqdqIH\n+gFLgOXAPbnMbwZMBxYA3wJNguY9CaQCi4Dn8H7sJK9HiSb6vXtVP/jAtajUquUOR9WqriJ6yhQ3\n/kw+PvvMrfJ//xe+kN55x23ztdfCt83ieP99LXPDtRpnxw7XlBQf78owZdX+/e5ObFD9+99LV5IP\n+P57d1Lt29e/4bqLleiB8sAKoCUQDyQDCTmWeQe42nveB3jDe3468L23jfLA/4Be+e0v4ol+xw7V\nN99UHTz46Pgydeq4O08++qhQdwGNHetW37IlfOEdOaLavbvq8ce785CfDh5UPfFE1YQEG2u+rNq6\nVTUx0fXqmjHD72gKb9cu124Fqs8/73c0+Rs/3sV5663+7L+4if404Mug1/cC9+ZYJhVo6j0XYFfQ\nunOBykAVYA7QNr/9RSTRb9x4bB/3Ro1c5fo33xR5dMirr3abCbfvvjtaevHT00+7OMIxMJTxz6ZN\nqu3auXJNOMd/ibQtW9zPL5Qv7wYBLAtGjXLfmVdfLfl9FzfRXwy8GvT6KuD5HMu8BdzqPR8EKFDX\nez0O2AHsBB7NYx8jvJPAnBNOOCE87/q339zdqT16uIbUQB/3O+9U/eGHsAxD16WL6jnnhCHWXPzx\nj6rVq5fcTSA5bdniarPOO8+f/ZvwWr/e3TlavbobO6+0W7vWnZwqVlT98EO/ownd4cPuO1OhQsmf\nVEsi0R8PvA/MB54F0oFaQCvgU6Ca9/gfcFZ++ytWiX7x4mx93BVUO3Rwd/oUo497bjIyXL/yv/41\nbJvMZvFiV5IZOTIy2y/ILbcU8ScPTamVnu6q4mrWLJ1jtQSsWOHKZNWqlc3qpu3b3Um1fv3CDV1e\nXPkl+jgKthZoGvS6iTcti6qu80ryiEg1YLCq7hCRG4AfVXWPN+9zrzrnuxD2WzirVkGbNu55t27w\nxBMwcCCcdFLYdxXY3f790L59RDZP69YwYgT85z9w881w8smR2U9uliyBf/8bbrghcu/PlLzGjWHG\nDOjRA845By65BFq1ghNPPPq3ShV/Y0xNdbEdPAjTp0PXrv7GUxS1asFHH7k0NGAAzJ4N1ar5HFRe\nZwA9WlqPA1YCLTjaGNsuxzL1gHLe80eBMd7zS4FvvG1UwPXMuSi//RWrRD9xYlYf90ibNs1dMETy\nMnjDBleqGTw4cvvITf/+7hLfxpqPTitWuFtC6tU7euEbeBx/vKvtvPZad3E8daob8reADmhh8dNP\nrl9Eo0al7lczi+SLL9xV8eDBJfODJRSnRK+qGSIyEvgS13NmvKqmisgYb8MfAb2Ax0VEgVnATd7q\n7+J64SzE1dt/oaofF+vMlJ9hwyK26ZxSUtzfhITI7aNhQ7jrLnjoIfjf/+C00yK3r4AZM1xp5PHH\n3f5N9GnZ0v2fAXbsgBUrYPny7I/PPoMNG7KvV7++K/nn9qhTp3gxzZwJ/ftDgwbw9dcuxrLuvPNg\n3Di47TYYMwZGj/YvFnEngtIjKSlJ58yZ43cYBRo6FH780VXhRNLeve6L1LKluwQUidy+MjMhKQm2\nb4fFi6FSpcjty5R+e/a4k0BuJ4I1a7IvW7v20aQfqAoKPBo0yP9z+9FHR6uRvvoKjj8+su+rJKnC\ntdfC66/DO+/AxRdHbl8iMldVk3KbF0odvclFSgq0axf5/VSt6koDI0bAtGmu2SFSJk2CX3+FyZMt\nyRtXr5yY6B457d/vCjnByX/FCvjpJ3j7bThyJPt2cl4BBE4GM2fC8OHQpYu7iqhbt+TeX0kQce1s\nS5fC1Ve799ypkw9xWIm+8A4fdgn4ttvgH/+I/P4yMtyX7fBh11hVoUL497Fnj2vwbdYMfvghslcO\nJrodOgS//XbsVcDy5e7kcPhw9uX79HGFmOrV/Ym3JGzc6K6WReCXXyJTLWol+jBbtsx9WEuqR0pc\nnOtEdNFF8Mor8Je/hH8fY8fC+vXw/vuW5E3xxMe7zm65dXjLzHTVPoHEf/Ag/OlP0X8F2bChq6I6\n4wwYPNj1KKpYseT2byX6Ipg6FS69FObPL7nLMFXo3RvS0twlcjhLP+nprjQ/YICrtjHGRMY777j2\niGuvhVdfDW+hKr8Sfbnw7SZ2pKRAuXJHu+2XBBFX6t68GZ58Mrzbvv9+V6f6+OPh3a4xJrshQ+DB\nB2H8eHjuuZLbryX6IkhJcY0qJX25eeqpcNll8NRTsG5deLY5Z45rhB01Cpo3D882jTF5Gz3adaq4\n7TbXy6gkWKIvgtRU/+4Yfewx1zj78MPF35aq+7DVrw/33lv87RljClaunCtctW/vqoCXLi2BfUZ+\nF9Fl/37XiORXom/RAkaOdJd+qanF29YHH8B338Ejj0CNGuGJzxhTsGrV4MMPXUeL/v3djWuRZIm+\nkBYvdvXZfo4Bc//9rjH27ruLvo2DB91dt+3awXXXhS82Y0xomjd3vdxWrHA3YGZmRm5flugLKTD0\ngZ+Jvm5dl+w//dTdcFIUL7zgPmBPPeVKFcaYknfWWW4AwS++KF7BrSCW6AspJcXdsNSqlb9x3Hwz\nnHAC3Hln9rsQQ7Fli7vbtl8/Nx6HMcY/N9zgvs9PPQUTJ0ZmH5boCyk11XWrjMTdqYVRqRI8+ijM\nnetuOS+MMWNg92434JIxxn9PPw1nnw0vvlj4glsoLNEXUkpK6Rmj/fLL3Q1b993n6txDsXixu1Qc\nMaJkxuoxxhQsLs7dTDV9uuuVE26W6Ath1y43hkdpSfTlyrmbqFavdnXuobjrLjdOz9/+FtHQjDGF\nVLu2+25GgiX6QkhLc39LS6IH6NvX1bX//e9ueOH8TJ8OH3/sGnIbNCiZ+Iwx/rNEXwiBHjelrcrj\niSdcP9zHHst7mcxMuP1216XrlltKLDRjTClgib4QUlOhcmV301Jp0rGjG+v6uedcNU5uJk6E5GR3\nUoj2kQKNMdlZoi+EwI+NRKKxpLgeecTF9eCDx87bs8dV15x2mhtUyRgTW0phyiq9SlOPm5yaNHED\nk/33vzBvXvZ5Tz7pfv/z6adtrHljYpEl+hBt2eKSZWlN9ODurKtXz91EFfiZgTVrXH/5oUOhe3d/\n4zPG+MMSfYgCA4iVtobYYDVrwkMPwYwZ8OWXbpqNNW+MsUQfokCiL80lenA/y9aqlSvV//QTvPGG\nG4q4WTO/IzPG+MUSfYhSUlyJuXFjvyPJX3y8K72npMAFF7j+8vfc43dUxhg/WaIPUaAhtiw0Zg4e\n7Orjt261seaNMZboQ6Jaunvc5CQCEya4X6G69lq/ozHG+M1GIg/B+vVueIHS3BCbU5s27rcpjTHG\nSvQhKCsNscYYkxtL9CEoDb8qZYwxRWWJPgQpKa73Sv36fkdijDGFF1KiF5F+IrJERJaLyDGd9USk\nmYhMF5EFIvKtiDQJmneCiHwlIotEJE1Emocv/JJRlhpijTEmpwITvYiUB14AzgcSgKEikpBjsXHA\nJFXtCIwBgu/DnASMVdW2QFdgUzgCLylHjrg6+rLUEGuMMcFCKdF3BZar6kpVPQRMAQbkWCYBmOE9\nnxmY750Q4lT1awBV3aOq+8ISeQn5/XfYu9dK9MaYsiuURN8YWBP0Ot2bFiwZGOQ9HwhUF5G6wMnA\nDhF5X0Tmi8hY7wohGxEZISJzRGTO5s2bC/8uIsgaYo0xZV24GmPvAHqKyHygJ7AWyMT10z/Lm38q\n0BK4JufKqvqyqiapalL9UtLmbGcAABlsSURBVNbiWVp/VcoYY0IVSqJfCzQNet3Em5ZFVdep6iBV\nPQW435u2A1f6/9Wr9skApgGdwxJ5CUlJgaZN3Tg3xhhTFoWS6H8BThKRFiISD1wGfBS8gIjUE5HA\ntu4FxgetW0tEAsX0PkBa8cMuOYFflTLGmLKqwETvlcRHAl8Ci4CpqpoqImNEpL+3WC9giYgsBRoC\nj3rrZuKqbaaLyEJAgFfC/i4iJCMDFi+2+nljTNkW0lg3qvoZ8FmOaQ8FPX8XeDePdb8GOhYjRt+s\nWAEHD1qiN8aUbXZnbD6sx40xJhpYos9HSoob8rdtW78jMcaYorNEn4+UFGjZEqpU8TsSY4wpOkv0\n+UhNtWobY0zZZ4k+DwcPwtKlluiNMWWfJfo8LFkCmZmW6I0xZZ8l+jxYjxtjTLSwRJ+HlBSIi4OT\nT/Y7EmOMKR5L9HlITXVJPj7e70iMMaZ4LNHnwX5VyhgTLSzR52LvXli50hK9MSY6WKLPRZo3vqYl\nemNMNLBEnwv7sRFjTDSxRJ+L1FSoWBFOPNHvSIwxpvgs0eciJQUSEqD8Mb9ua4wxZY8l+lxYjxtj\nTDSxRJ/D9u2wdq0lemNM9LBEn0NqqvtrDbHGmGhhiT6HQKK3Er0xJlpYos8hJQWqVYMTTvA7EmOM\nCQ9L9DkEGmJF/I7EGGPCwxJ9EFVYuNCqbYwx0cUSfZBNm2DrVmuINcZEF0v0Qawh1hgTjSzRB7Ff\nlTLGRCNL9EFSUqBuXWjY0O9IjDEmfCzRB7EeN8aYaGSJ3qPq6uitIdYYE20s0XvS02HXLqufN8ZE\nn5ASvYj0E5ElIrJcRO7JZX4zEZkuIgtE5FsRaZJjfg0RSReR58MVeLhZQ6wxJloVmOhFpDzwAnA+\nkAAMFZGEHIuNAyapakdgDPB4jvmPALOKH27k2K9KGWOiVSgl+q7AclVdqaqHgCnAgBzLJAAzvOcz\ng+eLSBegIfBV8cONnJQUaNQI6tTxOxJjjAmvUBJ9Y2BN0Ot0b1qwZGCQ93wgUF1E6opIOeAp4I78\ndiAiI0RkjojM2bx5c2iRh5n92IgxJlqFqzH2DqCniMwHegJrgUzgL8Bnqpqe38qq+rKqJqlqUv36\n9cMUUugyM2HRIkv0xpjoFBfCMmuBpkGvm3jTsqjqOrwSvYhUAwar6g4ROQ04S0T+AlQD4kVkj6oe\n06Drp1WrYP9+S/TGmOgUSqL/BThJRFrgEvxlwOXBC4hIPWCbqh4B7gXGA6jqFUHLXAMklbYkD9bj\nxhgT3QqsulHVDGAk8CWwCJiqqqkiMkZE+nuL9QKWiMhSXMProxGKNyICiT4hZ18iY4yJAqKqfseQ\nTVJSks6ZM6dE93nZZfDTT64KxxhjyiIRmauqSbnNsztjcUMfWLWNMSZaxXyiP3QIFi+2RG+MiV4x\nn+iXLYOMDEv0xpjoFfOJ3oY+MMZEO0v0KVCuHLRp43ckxhgTGTGf6FNT4aSToFIlvyMxxpjIiPlE\nb2PcGGOiXUwn+v37YflyS/TGmOgW04l+0SL3E4LWEGuMiWYxnehtjBtjTCyI6USfmgrx8dCqld+R\nGGNM5MR0ok9Jcd0qK1TwOxJjjImcmE/0Vm1jjIl2MZvod+2C33+3hlhjTPSL2USfmur+WoneGBPt\nLNFbojfGRLmYTfQpKVClCjRv7nckxhgTWTGd6Nu1cwOaGWNMNIvZNBdI9MYYE+1iMtFv2QIbN1r9\nvDEmNsRkoreGWGNMLInJRG9j3BhjYknMJvpateD44/2OxBhjIi9mE327diDidyTGGBN5MZfoVW2M\nG2NMbIm5RL9+PezYYYneGBM7Yi7RW0OsMSbWxGyit5uljDGxIiYTfYMGUL++35EYY0zJCCnRi0g/\nEVkiIstF5J5c5jcTkekiskBEvhWRJt70TiLyPxFJ9eZdGu43UFjWEGuMiTUFJnoRKQ+8AJwPJABD\nRSQhx2LjgEmq2hEYAzzuTd8HDFPVdkA/4BkRqRWu4AvryBFIS7NEb4yJLaGU6LsCy1V1paoeAqYA\nA3IskwDM8J7PDMxX1aWqusx7vg7YBPhWafLbb7B3ryV6Y0xsCSXRNwbWBL1O96YFSwYGec8HAtVF\npG7wAiLSFYgHVuTcgYiMEJE5IjJn8+bNocZeaNbjxhgTi8LVGHsH0FNE5gM9gbVAZmCmiDQC3gCG\nq+qRnCur6suqmqSqSfUj2EoaSPQJOSuejDEmisWFsMxaoGnQ6ybetCxetcwgABGpBgxW1R3e6xrA\np8D9qvpjOIIuqtRUaNoUatb0MwpjjClZoZTofwFOEpEWIhIPXAZ8FLyAiNQTkcC27gXGe9PjgQ9w\nDbXvhi/sorEeN8aYWFRgolfVDGAk8CWwCJiqqqkiMkZE+nuL9QKWiMhSoCHwqDf9EqAHcI2I/Oo9\nOoX7TYQiIwMWLbJEb4yJPaFU3aCqnwGf5Zj2UNDzd4FjSuyq+l/gv8WMMSyWL4dDhyzRG2NiT8zc\nGWtDHxhjYlXMJPrUVDf+fNu2fkdijDElK2YSfUoKnHgiVKnidyTGGFOyYirRW/28MSYWxUSiP3AA\nli2zRG+MiU0xkeiXLIHMTGuINcbEpphI9Kmp7q+V6I0xsSgmEn1KCsTFwckn+x2JMcaUvJhJ9K1b\nQ3y835EYY0zJi5lEb9U2xphYFfWJfs8eWLXKGmKNMbEr6hP9okXur5XojTGxKuoTvf2qlDEm1sVE\noq9UCVq29DsSY4zxR0wk+oQEKF/e70iMMcYfMZHorSHWGBPLojrRb98O69ZZ/bwxJrZFdaK3oQ+M\nMSbEnxIsq6zHjSnrDh8+THp6OgcOHPA7FFNKVKpUiSZNmlChQoWQ14n6RF+9OjRt6nckxhRNeno6\n1atXp3nz5oiI3+EYn6kqW7duJT09nRYtWoS8XlRX3QQaYu37YcqqAwcOULduXUvyBgARoW7duoW+\nwovaRK9qY9yY6GBJ3gQryuchahP9pk2wdaslemOMidpEbw2xxhTf1q1b6dSpE506deK4446jcePG\nWa8PHToU0jaGDx/OkiVL8l3mhRde4M033wxHyCYXUdsYa4nemOKrW7cuv/76KwCjR4+mWrVq3HHH\nHdmWUVVUlXLlci83TpgwocD93HTTTcUPtoRlZGQQF1c2UmhUl+jr1oUGDfyOxJgw+etfoVev8D7+\n+tcihbJ8+XISEhK44ooraNeuHevXr2fEiBEkJSXRrl07xowZk7XsmWeeya+//kpGRga1atXinnvu\nITExkdNOO41NmzYB8MADD/DMM89kLX/PPffQtWtXWrduzQ8//ADA3r17GTx4MAkJCVx88cUkJSVl\nnYSCPfzww5x66qm0b9+eP//5z6gqAEuXLqVPnz4kJibSuXNnVq9eDcBjjz1Ghw4dSExM5P77788W\nM8CGDRto1aoVAK+++ip//OMf6d27N+eddx67du2iT58+dO7cmY4dO/LJJ59kxTFhwgQ6duxIYmIi\nw4cPZ+fOnbRs2ZKMjAwAtm/fnu11JEVtok9NdaV5a8cyJjIWL17MqFGjSEtLo3HjxvzjH/9gzpw5\nJCcn8/XXX5OWlnbMOjt37qRnz54kJydz2mmnMX78+Fy3rar8/PPPjB07Nuuk8a9//YvjjjuOtLQ0\nHnzwQebPn5/rurfeeiu//PILCxcuZOfOnXzxxRcADB06lFGjRpGcnMwPP/xAgwYN+Pjjj/n888/5\n+eefSU5O5vbbby/wfc+fP5/333+f6dOnU7lyZaZNm8a8efP45ptvGDVqFADJyck88cQTfPvttyQn\nJ/PUU09Rs2ZNzjjjjKx4Jk+ezJAhQ0rkqqBsXHcUUqDHzbBhfkdiTBh5Jd7S4sQTTyQpKSnr9eTJ\nk3nttdfIyMhg3bp1pKWlkZCQkG2dypUrc/755wPQpUsXvvvuu1y3PWjQoKxlAiXv2bNnc/fddwOQ\nmJhIuzwGsZo+fTpjx47lwIEDbNmyhS5dutC9e3e2bNnCRRddBLibjgC++eYbrr32WipXrgxAnTp1\nCnzf5557LrVr1wbcCemee+5h9uzZlCtXjjVr1rBlyxZmzJjBpZdemrW9wN/rr7+e5557jgsvvJAJ\nEybwxhtvFLi/cIjKRL9mDezebfXzxkRS1apVs54vW7aMZ599lp9//platWpx5ZVX5trXOz7oh5vL\nly+fZ7VFxYoVC1wmN/v27WPkyJHMmzePxo0b88ADDxTpruK4uDiOHDkCcMz6we970qRJ7Ny5k3nz\n5hEXF0eTJk3y3V/Pnj0ZOXIkM2fOpEKFCrRp06bQsRVFSFU3ItJPRJaIyHIRuSeX+c1EZLqILBCR\nb0WkSdC8q0Vkmfe4OpzB58UaYo0pWbt27aJ69erUqFGD9evX8+WXX4Z9H2eccQZTp04FYOHChblW\nDe3fv59y5cpRr149du/ezXvvvQdA7dq1qV+/Ph9//DHgkve+ffs455xzGD9+PPv37wdg27ZtADRv\n3py5c+cC8O677+YZ086dO2nQoAFxcXF8/fXXrF27FoA+ffrw9ttvZ20v8Bfgyiuv5IorrmD48OHF\nOh6FUWCiF5HywAvA+UACMFREEnIsNg6YpKodgTHA4966dYCHgW5AV+BhEakdvvBzF0j0NjyxMSWj\nc+fOJCQk0KZNG4YNG8YZZ5wR9n3cfPPNrF27loSEBP72t7+RkJBAzZo1sy1Tt25drr76ahISEjj/\n/PPp1q1b1rw333yTp556io4dO3LmmWeyefNmLrzwQvr160dSUhKdOnXin//8JwB33nknzz77LJ07\nd2b79u15xnTVVVfxww8/0KFDB6ZMmcJJJ50EuKqlu+66ix49etCpUyfuvPPOrHWuuOIKdu7cyaWX\nXhrOw5O/QNeovB7AacCXQa/vBe7NsUwq0NR7LsAu7/lQ4KWg5V4Chua3vy5dumhxDRumevzxxd6M\nMb5LS0vzO4RS4/Dhw7p//35VVV26dKk2b95cDx8+7HNUhTd58mS95pprirWN3D4XwBzNI6+GUkff\nGFgT9DodV0IPlgwMAp4FBgLVRaRuHus2zrkDERkBjAA44YQTQggpfzb0gTHRZ8+ePZx99tlkZGSg\nqrz00ktlph97wI033sg333yT1fOmpITrKN0BPC8i1wCzgLVAZqgrq+rLwMsASUlJWpxAMjMhLQ3+\n8pfibMUYU9rUqlUrq968rHrxxRd92W8oiX4tEDzQbxNvWhZVXYcr0SMi1YDBqrpDRNYCvXKs+20x\n4i3QypVw4ICV6I0xJiCUXje/ACeJSAsRiQcuAz4KXkBE6olIYFv3AoG7IL4EzhWR2l4j7LnetIix\nhlhjjMmuwESvqhnASFyCXgRMVdVUERkjIv29xXoBS0RkKdAQeNRbdxvwCO5k8QswxpsWMYGfD0zI\n2S/IGGNiVEh19Kr6GfBZjmkPBT1/F8i1s6mqjudoCT/iUlKgRQuoVq2k9miMMaVb1I11Yz1ujAmf\n3r17H3Pz0zPPPMONN96Y73rVvJLWunXruPjii3NdplevXsyZMyff7TzzzDPs27cv6/Uf/vAHduzY\nEUroJkhUJfpDh2DJEqufNyZchg4dypQpU7JNmzJlCkOHDg1p/eOPPz7fO0sLkjPRf/bZZ9SqVavI\n2ytpqpo1lIKfoirRL10KGRlWojfRyY9Rii+++GI+/fTTrB8ZWb16NevWreOss87K6tfeuXNnOnTo\nwIcffnjM+qtXr6a994Xcv38/l112GW3btmXgwIFZww6A618eGOL44YcfBuC5555j3bp19O7dm969\newNuaIItW7YA8PTTT9O+fXvat2+fNcTx6tWradu2LTfccAPt2rXj3HPPzbafgI8//phu3bpxyimn\n0LdvXzZu3Ai4vvrDhw+nQ4cOdOzYMWsIhS+++ILOnTuTmJjI2WefDbjx+ceNG5e1zfbt27N69WpW\nr15N69atGTZsGO3bt2fNmjW5vj+AX375hdNPP53ExES6du3K7t276dGjR7bhl88880ySk5Pz/0cV\noGzdbVCAQEOsJXpjwqNOnTp07dqVzz//nAEDBjBlyhQuueQSRIRKlSrxwQcfUKNGDbZs2UL37t3p\n379/nr9p+uKLL1KlShUWLVrEggUL6Ny5c9a8Rx99lDp16pCZmcnZZ5/NggULuOWWW3j66aeZOXMm\n9erVy7atuXPnMmHCBH766SdUlW7dutGzZ09q167NsmXLmDx5Mq+88gqXXHIJ7733HldeeWW29c88\n80x+/PFHRIRXX32VJ598kqeeeopHHnmEmjVrsnDhQsCNGb9582ZuuOEGZs2aRYsWLbKNW5OXZcuW\nMXHiRLp3757n+2vTpg2XXnopb7/9Nqeeeiq7du2icuXKXHfddbz++us888wzLF26lAMHDpCYmFio\n/1tOUZXoU1KgfHlo3drvSIwJP79GKQ5U3wQS/WuvvQa4aon77ruPWbNmUa5cOdauXcvGjRs57rjj\nct3OrFmzuOWWWwDo2LEjHTt2zJo3depUXn75ZTIyMli/fj1paWnZ5uc0e/ZsBg4cmDWS5KBBg/ju\nu+/o378/LVq0oFOnTkD2YY6Dpaenc+mll7J+/XoOHTpEixYtADdscXBVVe3atfn444/p0aNH1jKh\nDGXcrFmzrCSf1/sTERo1asSpp54KQI0aNQAYMmQIjzzyCGPHjmX8+PFcc801Be6vIFFVdZOSAied\nBN5Q08aYMBgwYADTp09n3rx57Nu3jy5dugBukLDNmzczd+5cfv31Vxo2bFikIYFXrVrFuHHjmD59\nOgsWLOCCCy4o0nYCAkMcQ97DHN98882MHDmShQsX8tJLLxV7KGPIPpxx8FDGhX1/VapU4ZxzzuHD\nDz9k6tSpXHHFFYWOLaeoS/TWEGtMeFWrVo3evXtz7bXXZmuEDQzRW6FCBWbOnMlvv/2W73Z69OjB\nW2+9BUBKSgoLFiwA3BDHVatWpWbNmmzcuJHPP/88a53q1auze/fuY7Z11llnMW3aNPbt28fevXv5\n4IMPOOuss0J+Tzt37qRxYzfs1sSJE7Omn3POObzwwgtZr7dv30737t2ZNWsWq1atArIPZTxv3jwA\n5s2blzU/p7zeX+vWrVm/fj2//PILALt37846KV1//fXccsstnHrqqVk/clIcUZPo9+2DFSusft6Y\nSBg6dCjJycnZEv0VV1zBnDlz6NChA5MmTSrwRzRuvPFG9uzZQ9u2bXnooYeyrgwSExM55ZRTaNOm\nDZdffnm2IY5HjBhBv379shpjAzp37sw111xD165d6datG9dffz2nnHJKyO9n9OjRDBkyhC5dumSr\n/3/ggQfYvn077du3JzExkZkzZ1K/fn1efvllBg0aRGJiYtbwwoMHD2bbtm20a9eO559/npNPPjnX\nfeX1/uLj43n77be5+eabSUxM5Jxzzskq6Xfp0oUaNWqEbcx6US3WGGJhl5SUpAX1rc3Npk0wahQM\nHw59+0YgMGN8sGjRItq2bet3GKaErVu3jl69erF48WLKlTu2PJ7b50JE5qpq0jELE0Ul+gYN4M03\nLckbY8q2SZMm0a1bNx599NFck3xRRFWvG2OMKeuGDRvGsGHDwrrNqCnRGxOtSlv1qvFXUT4PluiN\nKcUqVarE1q1bLdkbwCX5rVu3UqmQfcit6saYUqxJkyakp6ezefNmv0MxpUSlSpVo0qRJodaxRG9M\nKVahQoWsOzKNKSqrujHGmChnid4YY6KcJXpjjIlype7OWBHZDOQ/aEb+6gFbwhROWWfHIjs7HtnZ\n8TgqGo5FM1Wtn9uMUpfoi0tE5uR1G3CssWORnR2P7Ox4HBXtx8KqbowxJspZojfGmCgXjYn+Zb8D\nKEXsWGRnxyM7Ox5HRfWxiLo6emOMMdlFY4neGGNMEEv0xhgT5aIm0YtIPxFZIiLLReQev+Pxk4g0\nFZGZIpImIqkicqvfMflNRMqLyHwR+cTvWPwmIrVE5F0RWSwii0TkNL9j8pOIjPK+JykiMllECjc0\nZBkQFYleRMoDLwDnAwnAUBFJ8DcqX2UAt6tqAtAduCnGjwfArcAiv4MoJZ4FvlDVNkAiMXxcRKQx\ncAuQpKrtgfLAZf5GFX5RkeiBrsByVV2pqoeAKcAAn2PyjaquV9V53vPduC9yY3+j8o+INAEuAF71\nOxa/iUhNoAfwGoCqHlLVHf5G5bs4oLKIxAFVgHU+xxN20ZLoGwNrgl6nE8OJLZiINAdOAX7yNxJf\nPQPcBRzxO5BSoAWwGZjgVWW9KiJV/Q7KL6q6FhgH/A6sB3aq6lf+RhV+0ZLoTS5EpBrwHvBXVd3l\ndzx+EJELgU2qOtfvWEqJOKAz8KKqngLsBWK2TUtEauOu/lsAxwNVReRKf6MKv2hJ9GuBpkGvm3jT\nYpaIVMAl+TdV9X2/4/HRGUB/EVmNq9LrIyL/9TckX6UD6aoauMJ7F5f4Y1VfYJWqblbVw8D7wOk+\nxxR20ZLofwFOEpEWIhKPa0z5yOeYfCMigquDXaSqT/sdj59U9V5VbaKqzXGfixmqGnUltlCp6gZg\njYi09iadDaT5GJLffge6i0gV73tzNlHYOB0VPyWoqhkiMhL4EtdqPl5VU30Oy09nAFcBC0XkV2/a\nfar6mY8xmdLjZuBNr1C0Ehjuczy+UdWfRORdYB6ut9p8onA4BBsCwRhjoly0VN0YY4zJgyV6Y4yJ\ncpbojTEmylmiN8aYKGeJ3hhjopwlemOMiXKW6I0xJsr9Pw6yRQjrLu6LAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG0hN3SMC1Qj",
        "colab_type": "code",
        "outputId": "3c77ffe9-a7f7-4994-ea68-a94f5e2be436",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path='/content/' + fn\n",
        "  img=image.load_img(path, target_size=(256, 256))\n",
        "  \n",
        "  x=image.img_to_array(img)/255\n",
        "  #print(x.shape())\n",
        "  x=np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  print(classes)\n",
        "\n",
        "  if classes>0.5:\n",
        "    print(fn + \" ther is a fish\")\n",
        "    \n",
        "  else:\n",
        "    print(fn + \" ther is no fish\")\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7e2a634f-077c-43d0-8061-705a1c085127\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7e2a634f-077c-43d0-8061-705a1c085127\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving f01.png to f01 (1).png\n",
            "Saving f1.jpg to f1 (1).jpg\n",
            "Saving f02.jpg to f02 (1).jpg\n",
            "Saving f2.jpg to f2 (1).jpg\n",
            "Saving f03.jpg to f03 (1).jpg\n",
            "Saving f3.jpg to f3 (1).jpg\n",
            "Saving f04.jpg to f04 (1).jpg\n",
            "Saving f4.jpg to f4 (1).jpg\n",
            "Saving f05.jpg to f05 (1).jpg\n",
            "Saving f5.jpg to f5 (1).jpg\n",
            "Saving f06.jpg to f06 (1).jpg\n",
            "Saving f6.jpg to f6 (1).jpg\n",
            "Saving f07.jpg to f07 (1).jpg\n",
            "Saving f7.jpg to f7 (1).jpg\n",
            "Saving f08.jpg to f08 (1).jpg\n",
            "Saving f8.jpg to f8 (1).jpg\n",
            "Saving f09.jpg to f09 (1).jpg\n",
            "Saving f9.jpg to f9 (1).jpg\n",
            "Saving f10_cat.jpg to f10_cat.jpg\n",
            "Saving f11_brid.jpg to f11_brid.jpg\n",
            "Saving f12_Wolf8.jpg to f12_Wolf8.jpg\n",
            "Saving f13_notfish.jpg to f13_notfish.jpg\n",
            "Saving f14_dog.jpg to f14_dog.jpg\n",
            "Saving f15_dog2.jpg to f15_dog2.jpg\n",
            "Saving f16_notfish.jpg to f16_notfish.jpg\n",
            "Saving f17_dog3.jpg to f17_dog3.jpg\n",
            "[[1.]]\n",
            "f01.png ther is a fish\n",
            "[[1.]]\n",
            "f1.jpg ther is a fish\n",
            "[[1.]]\n",
            "f02.jpg ther is a fish\n",
            "[[1.]]\n",
            "f2.jpg ther is a fish\n",
            "[[1.]]\n",
            "f03.jpg ther is a fish\n",
            "[[1.]]\n",
            "f3.jpg ther is a fish\n",
            "[[1.]]\n",
            "f04.jpg ther is a fish\n",
            "[[1.]]\n",
            "f4.jpg ther is a fish\n",
            "[[1.]]\n",
            "f05.jpg ther is a fish\n",
            "[[1.]]\n",
            "f5.jpg ther is a fish\n",
            "[[1.]]\n",
            "f06.jpg ther is a fish\n",
            "[[1.]]\n",
            "f6.jpg ther is a fish\n",
            "[[1.]]\n",
            "f07.jpg ther is a fish\n",
            "[[0.16775833]]\n",
            "f7.jpg ther is no fish\n",
            "[[1.]]\n",
            "f08.jpg ther is a fish\n",
            "[[1.]]\n",
            "f8.jpg ther is a fish\n",
            "[[1.]]\n",
            "f09.jpg ther is a fish\n",
            "[[1.]]\n",
            "f9.jpg ther is a fish\n",
            "[[0.]]\n",
            "f10_cat.jpg ther is no fish\n",
            "[[0.999866]]\n",
            "f11_brid.jpg ther is a fish\n",
            "[[1.]]\n",
            "f12_Wolf8.jpg ther is a fish\n",
            "[[0.]]\n",
            "f13_notfish.jpg ther is no fish\n",
            "[[0.99986887]]\n",
            "f14_dog.jpg ther is a fish\n",
            "[[0.]]\n",
            "f15_dog2.jpg ther is no fish\n",
            "[[0.]]\n",
            "f16_notfish.jpg ther is no fish\n",
            "[[0.]]\n",
            "f17_dog3.jpg ther is no fish\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}