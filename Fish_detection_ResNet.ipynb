{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fish detection_ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmad-AlShalabi/Fish-detection/blob/master/Fish_detection_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcMgtG6TZJ-E",
        "colab_type": "code",
        "outputId": "3947ed6a-41f5-4940-8ad8-565e600df393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!mkdir -p /content/data/\n",
        "!wget --no-check-certificate \\\n",
        "  https://www.dropbox.com/s/e2xya1pzr2tm9xr/QUT_fish_data.zip\\\n",
        "  -O /content/data/QUT_fish_data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-13 06:06:44--  https://www.dropbox.com/s/e2xya1pzr2tm9xr/QUT_fish_data.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/e2xya1pzr2tm9xr/QUT_fish_data.zip [following]\n",
            "--2019-11-13 06:06:45--  https://www.dropbox.com/s/raw/e2xya1pzr2tm9xr/QUT_fish_data.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc1094d7f0484904d82e566bfd09.dl.dropboxusercontent.com/cd/0/inline/AsSS7kfO3qJBueu6L4TCBYQcggJX6-lwozcSR9uJ0ZpKUdxJEl0yHN6B2oD4x-9rJLPJsbxV0vXqAYn7f2bWyXweLZsXFGxOb-PEN0sGvYd-aw/file# [following]\n",
            "--2019-11-13 06:06:45--  https://uc1094d7f0484904d82e566bfd09.dl.dropboxusercontent.com/cd/0/inline/AsSS7kfO3qJBueu6L4TCBYQcggJX6-lwozcSR9uJ0ZpKUdxJEl0yHN6B2oD4x-9rJLPJsbxV0vXqAYn7f2bWyXweLZsXFGxOb-PEN0sGvYd-aw/file\n",
            "Resolving uc1094d7f0484904d82e566bfd09.dl.dropboxusercontent.com (uc1094d7f0484904d82e566bfd09.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to uc1094d7f0484904d82e566bfd09.dl.dropboxusercontent.com (uc1094d7f0484904d82e566bfd09.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AsR7NtTS7Gn08ojA5yEhlRVt5ABbSW528eWynNiWkRB4-EQIyEc9bxZecEOSm1WaM3pCQqPQOqqIodXNTc_KDBXBcOqml6_WC54TU8O5ZPuu0y3E8H7bTopFxqRIHX11NYwpYyvBev5T4i6XZxIGSS8HsYJOLR7E65u8WfnfCRvdZYUKSxqcM0T9wiSx4WcpYJtyNHomZvcSdkjIhLUtLtyFoyVm8P0_4uQqp1IxAsUWeiIvmKthF1Gfh5nasw4ZkQP_WAs2nDf6BMeAhNGfJJ6lES-hNhFSmZiltg30_jKSNKRuT60FDHfYtQ3CNs3Y2ti-TjbeUzXUISp34gIbMSop/file [following]\n",
            "--2019-11-13 06:06:46--  https://uc1094d7f0484904d82e566bfd09.dl.dropboxusercontent.com/cd/0/inline2/AsR7NtTS7Gn08ojA5yEhlRVt5ABbSW528eWynNiWkRB4-EQIyEc9bxZecEOSm1WaM3pCQqPQOqqIodXNTc_KDBXBcOqml6_WC54TU8O5ZPuu0y3E8H7bTopFxqRIHX11NYwpYyvBev5T4i6XZxIGSS8HsYJOLR7E65u8WfnfCRvdZYUKSxqcM0T9wiSx4WcpYJtyNHomZvcSdkjIhLUtLtyFoyVm8P0_4uQqp1IxAsUWeiIvmKthF1Gfh5nasw4ZkQP_WAs2nDf6BMeAhNGfJJ6lES-hNhFSmZiltg30_jKSNKRuT60FDHfYtQ3CNs3Y2ti-TjbeUzXUISp34gIbMSop/file\n",
            "Reusing existing connection to uc1094d7f0484904d82e566bfd09.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1411537902 (1.3G) [application/zip]\n",
            "Saving to: ‘/content/data/QUT_fish_data.zip’\n",
            "\n",
            "/content/data/QUT_f 100%[===================>]   1.31G  52.1MB/s    in 27s     \n",
            "\n",
            "2019-11-13 06:07:14 (49.3 MB/s) - ‘/content/data/QUT_fish_data.zip’ saved [1411537902/1411537902]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzg3KfJkoFcQ",
        "colab_type": "code",
        "outputId": "e3a7035c-f13e-49ad-977b-ac665de9e278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://www.dropbox.com/s/p2a4rwv9x8cf78a/not_fish_data.zip?dl= \\\n",
        "  -O /content/data/not_fish_data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-13 06:07:19--  https://www.dropbox.com/s/p2a4rwv9x8cf78a/not_fish_data.zip?dl=\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/p2a4rwv9x8cf78a/not_fish_data.zip [following]\n",
            "--2019-11-13 06:07:20--  https://www.dropbox.com/s/raw/p2a4rwv9x8cf78a/not_fish_data.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc454a2857c790ca03763b16f435.dl.dropboxusercontent.com/cd/0/inline/AsSyvVBvmSWi7zYWa6Hbqf2aoFgGZnOFbZf3utwfv6wwD4DkfDB4kHY-qg22g0xNGZCxefJAvcCT855ht22122CtU-wbF0oxXSenkDTslBhnVSQ4Qczw2j6Bjniv37Il8ng/file# [following]\n",
            "--2019-11-13 06:07:20--  https://uc454a2857c790ca03763b16f435.dl.dropboxusercontent.com/cd/0/inline/AsSyvVBvmSWi7zYWa6Hbqf2aoFgGZnOFbZf3utwfv6wwD4DkfDB4kHY-qg22g0xNGZCxefJAvcCT855ht22122CtU-wbF0oxXSenkDTslBhnVSQ4Qczw2j6Bjniv37Il8ng/file\n",
            "Resolving uc454a2857c790ca03763b16f435.dl.dropboxusercontent.com (uc454a2857c790ca03763b16f435.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uc454a2857c790ca03763b16f435.dl.dropboxusercontent.com (uc454a2857c790ca03763b16f435.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AsQ89D0b8zMy-Q9sTcFT6guozJwq-t1ZlxF4Baqo0qknG-kGTF5nNV1m_G3zIW4XPp1gI53rGq2PaLrGPnbgIl46w7P_6tmjuppeX5rLZfVr2r3b6G5K8EzU1d9EdWYZyW0COt_g6FEq-wrZn2R11vB3DffgbpFWOjKBMwa2bToeNwU19KwDQtF3TO20pWRypFKRGnZQdkQy0QJsfGSYD6vCfWpjTwN-CUD0M-3xxGq476qU5AQ0xBrSOT3DsiMNk2dlVdyPTvBf4zlVnUdpACrXsNIiy9m3w8vP725DnxkpaSSj09A-w0P-LHV6Y1zSLtDdEj-vNwOM7nAuamrxIl_Cbd8wxg5zEVWbDKKfu7fQzw/file [following]\n",
            "--2019-11-13 06:07:20--  https://uc454a2857c790ca03763b16f435.dl.dropboxusercontent.com/cd/0/inline2/AsQ89D0b8zMy-Q9sTcFT6guozJwq-t1ZlxF4Baqo0qknG-kGTF5nNV1m_G3zIW4XPp1gI53rGq2PaLrGPnbgIl46w7P_6tmjuppeX5rLZfVr2r3b6G5K8EzU1d9EdWYZyW0COt_g6FEq-wrZn2R11vB3DffgbpFWOjKBMwa2bToeNwU19KwDQtF3TO20pWRypFKRGnZQdkQy0QJsfGSYD6vCfWpjTwN-CUD0M-3xxGq476qU5AQ0xBrSOT3DsiMNk2dlVdyPTvBf4zlVnUdpACrXsNIiy9m3w8vP725DnxkpaSSj09A-w0P-LHV6Y1zSLtDdEj-vNwOM7nAuamrxIl_Cbd8wxg5zEVWbDKKfu7fQzw/file\n",
            "Reusing existing connection to uc454a2857c790ca03763b16f435.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43840702 (42M) [application/zip]\n",
            "Saving to: ‘/content/data/not_fish_data.zip’\n",
            "\n",
            "/content/data/not_f 100%[===================>]  41.81M  58.6MB/s    in 0.7s    \n",
            "\n",
            "2019-11-13 06:07:22 (58.6 MB/s) - ‘/content/data/not_fish_data.zip’ saved [43840702/43840702]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0GUdLG4FnIa",
        "colab_type": "code",
        "outputId": "249c630d-c5c2-456b-cd2f-5c47a2732ba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E__v__ysvdTU",
        "colab_type": "code",
        "outputId": "8de20776-49ce-41e2-ec12-7f018a7107c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import random\n",
        "from shutil import copyfile\n",
        "\n",
        "local_zip = '/content/data/QUT_fish_data.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/data/')\n",
        "zip_ref.close()\n",
        "\n",
        "try:\n",
        "    os.mkdir('/content/data/images')\n",
        "    os.mkdir('/content/data/images/training')\n",
        "    os.mkdir('/content/data/images/testing')\n",
        "    os.mkdir('/content/data/images/training/pos')\n",
        "    os.mkdir('/content/data/images/testing/pos')\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    files = []\n",
        "    for filename in os.listdir(SOURCE):\n",
        "        file = SOURCE + filename\n",
        "        if os.path.getsize(file) > 0:\n",
        "            files.append(filename)\n",
        "        else:\n",
        "            print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "    training_length = int(len(files) * SPLIT_SIZE)\n",
        "    testing_length = int(len(files) - training_length)\n",
        "    shuffled_set = random.sample(files, len(files))\n",
        "    training_set = shuffled_set[0:training_length]\n",
        "    testing_set = shuffled_set[-testing_length:]\n",
        "\n",
        "    for filename in training_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TRAINING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "    for filename in testing_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TESTING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "\n",
        "FISH_SOURCE_DIR = \"/content/data/QUT_fish_data/images/raw_images/\"\n",
        "TRAINING_FISH_DIR = \"/content/data/images/training/pos/\"\n",
        "TESTING_FISH_DIR = \"/content/data/images/testing/pos/\"\n",
        "\n",
        "split_size = .7\n",
        "split_data(FISH_SOURCE_DIR, TRAINING_FISH_DIR, TESTING_FISH_DIR, split_size)\n",
        "\n",
        "print(len(os.listdir('/content/data/images/training/pos/')))\n",
        "print(len(os.listdir('/content/data/images/testing/pos/')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3084\n",
            "1322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzjsKUTNHkQw",
        "colab_type": "code",
        "outputId": "9c974ec5-f4f7-4f3c-a526-ad3564382a01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "local_zip = '/content/data/not_fish_data.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/data/')\n",
        "zip_ref.close()\n",
        "\n",
        "try:\n",
        "    os.mkdir('/content/data/images/training/neg')\n",
        "    os.mkdir('/content/data/images/testing/neg')\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "NoFISH_SOURCE_DIR = \"/content/data/not_fish/\"\n",
        "TRAINING_NoFISH_DIR = \"/content/data/images/training/neg/\"\n",
        "TESTING_NoFISH_DIR = \"/content/data/images/testing/neg/\"\n",
        "\n",
        "split_size = .7\n",
        "split_data(NoFISH_SOURCE_DIR, TRAINING_NoFISH_DIR, TESTING_NoFISH_DIR, split_size)\n",
        "\n",
        "print(len(os.listdir('/content/data/images/training/neg/')))\n",
        "print(len(os.listdir('/content/data/images/testing/neg/')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2795\n",
            "1198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWVwfwiJIDYI",
        "colab_type": "code",
        "outputId": "0e571dc4-b111-4d03-c336-0b7af82bc480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "base_model = tf.keras.applications.resnet_v2.ResNet50V2(include_top=False, weights='imagenet', input_shape=(256,256,3), pooling=None )\n",
        "\n",
        "\n",
        "'''for layer in base_model.layers:\n",
        "      layer.trainable = False'''\n",
        "#x = layers.MaxPooling2D() (base_model.output)\n",
        "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)\n",
        "model = Model(base_model.input, x)\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 64, 64, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 64, 64, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 64, 64, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 64, 64, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 64, 64, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 32, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 32, 32, 256)  0           max_pooling2d[0][0]              \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 32, 32, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 32, 32, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 32, 32, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 512)  0           conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 16, 16, 512)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 16, 16, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 16, 16, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 1024)   0           conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 8, 8, 1024)   0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 8, 8, 1024)   4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 8, 8, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 8, 8, 2048)   8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 8, 8, 2048)   0           post_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           post_relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          1049088     global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            513         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 24,614,401\n",
            "Trainable params: 24,568,961\n",
            "Non-trainable params: 45,440\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42w2rX2nL_al",
        "colab_type": "code",
        "outputId": "19840cac-ba4e-45b4-8669-86d3e1f7c41e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=180,\n",
        "      width_shift_range=0.3,\n",
        "      height_shift_range=0.3,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=-0.2,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/data/images/training/',  # This is the source directory for training images\n",
        "        target_size=(256, 256),  # All images will be resized to 256x256\n",
        "        batch_size=28,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/data/images/testing',  # This is the source directory for training images\n",
        "        target_size=(256, 256),  # All images will be resized to 256x256\n",
        "        batch_size=24,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5878 images belonging to 2 classes.\n",
            "Found 2520 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MToARslrbTZ",
        "colab_type": "code",
        "outputId": "63dda8bb-1a4d-483f-ef65-53ecd586498e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "      \n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 10,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Epoch 1/10\n",
            "100/100 - 91s - loss: 0.0333 - acc: 0.9925 - val_loss: 0.0608 - val_acc: 0.9942\n",
            "Epoch 2/10\n",
            "Epoch 1/10\n",
            "100/100 - 90s - loss: 0.0176 - acc: 0.9950 - val_loss: 1.0713 - val_acc: 0.9667\n",
            "Epoch 3/10\n",
            "Epoch 1/10\n",
            "100/100 - 91s - loss: 0.0285 - acc: 0.9921 - val_loss: 44.1153 - val_acc: 0.7783\n",
            "Epoch 4/10\n",
            "Epoch 1/10\n",
            "100/100 - 91s - loss: 0.0414 - acc: 0.9921 - val_loss: 7.4737 - val_acc: 0.8700\n",
            "Epoch 5/10\n",
            "Epoch 1/10\n",
            "100/100 - 91s - loss: 0.0237 - acc: 0.9943 - val_loss: 0.3080 - val_acc: 0.9867\n",
            "Epoch 6/10\n",
            "Epoch 1/10\n",
            "100/100 - 90s - loss: 0.0294 - acc: 0.9950 - val_loss: 0.0648 - val_acc: 0.9825\n",
            "Epoch 7/10\n",
            "Epoch 1/10\n",
            "100/100 - 91s - loss: 0.0214 - acc: 0.9950 - val_loss: 3.4608 - val_acc: 0.9517\n",
            "Epoch 8/10\n",
            "Epoch 1/10\n",
            "100/100 - 91s - loss: 0.0271 - acc: 0.9911 - val_loss: 7.8130 - val_acc: 0.8033\n",
            "Epoch 9/10\n",
            "Epoch 1/10\n",
            "100/100 - 91s - loss: 0.0182 - acc: 0.9950 - val_loss: 0.1502 - val_acc: 0.9917\n",
            "Epoch 10/10\n",
            "Epoch 1/10\n",
            "100/100 - 91s - loss: 0.1496 - acc: 0.9904 - val_loss: 0.0239 - val_acc: 0.9950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbG5GccsXgMM",
        "colab_type": "code",
        "outputId": "bfa8bfc1-9c15-4eaa-e00e-8a4b321cfb77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nihLlqNAriqJEOf8fD6a1eK3a//gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG0hN3SMC1Qj",
        "colab_type": "code",
        "outputId": "9a3f8daa-3b4e-4213-9275-4a4a3f91167d",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path='/content/' + fn\n",
        "  img=image.load_img(path, target_size=(256, 256))\n",
        "  \n",
        "  x=image.img_to_array(img)/255\n",
        "  #print(x.shape())\n",
        "  x=np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  print(classes)\n",
        "\n",
        "  if classes>0.5:\n",
        "    print(fn + \" ther is a fish\")\n",
        "    \n",
        "  else:\n",
        "    print(fn + \" ther is no fish\")\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3a523933-d4c0-47b3-b3ce-1f5454d48734\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-3a523933-d4c0-47b3-b3ce-1f5454d48734\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving f01.png to f01 (2).png\n",
            "Saving f1.jpg to f1 (2).jpg\n",
            "Saving f02.jpg to f02 (2).jpg\n",
            "Saving f2.jpg to f2 (2).jpg\n",
            "Saving f03.jpg to f03 (3).jpg\n",
            "Saving f3.jpg to f3 (2).jpg\n",
            "Saving f04.jpg to f04 (2).jpg\n",
            "Saving f4.jpg to f4 (3).jpg\n",
            "Saving f05.jpg to f05 (2).jpg\n",
            "Saving f5.jpg to f5 (2).jpg\n",
            "Saving f06.jpg to f06 (2).jpg\n",
            "Saving f6.jpg to f6 (2).jpg\n",
            "Saving f07.jpg to f07 (2).jpg\n",
            "Saving f7.jpg to f7 (2).jpg\n",
            "Saving f08.jpg to f08 (2).jpg\n",
            "Saving f8.jpg to f8 (2).jpg\n",
            "Saving f09.jpg to f09 (2).jpg\n",
            "Saving f9.jpg to f9 (2).jpg\n",
            "Saving f10_cat.jpg to f10_cat (1).jpg\n",
            "Saving f11_brid.jpg to f11_brid (1).jpg\n",
            "Saving f12_Wolf8.jpg to f12_Wolf8 (1).jpg\n",
            "Saving f13_notfish.jpg to f13_notfish (1).jpg\n",
            "Saving f14_dog.jpg to f14_dog (1).jpg\n",
            "Saving f15_dog2.jpg to f15_dog2 (1).jpg\n",
            "Saving f16_notfish.jpg to f16_notfish (1).jpg\n",
            "Saving f17_dog3.jpg to f17_dog3 (1).jpg\n",
            "[[0.9994497]]\n",
            "f01.png ther is a fish\n",
            "[[1.]]\n",
            "f1.jpg ther is a fish\n",
            "[[1.]]\n",
            "f02.jpg ther is a fish\n",
            "[[1.]]\n",
            "f2.jpg ther is a fish\n",
            "[[0.7601347]]\n",
            "f03.jpg ther is a fish\n",
            "[[1.]]\n",
            "f3.jpg ther is a fish\n",
            "[[0.26588863]]\n",
            "f04.jpg ther is no fish\n",
            "[[1.0196747e-07]]\n",
            "f4.jpg ther is no fish\n",
            "[[1.]]\n",
            "f05.jpg ther is a fish\n",
            "[[0.9999999]]\n",
            "f5.jpg ther is a fish\n",
            "[[0.99999964]]\n",
            "f06.jpg ther is a fish\n",
            "[[0.99999964]]\n",
            "f6.jpg ther is a fish\n",
            "[[1.]]\n",
            "f07.jpg ther is a fish\n",
            "[[1.]]\n",
            "f7.jpg ther is a fish\n",
            "[[0.]]\n",
            "f08.jpg ther is no fish\n",
            "[[0.998906]]\n",
            "f8.jpg ther is a fish\n",
            "[[0.9999733]]\n",
            "f09.jpg ther is a fish\n",
            "[[1.]]\n",
            "f9.jpg ther is a fish\n",
            "[[0.]]\n",
            "f10_cat.jpg ther is no fish\n",
            "[[0.99997747]]\n",
            "f11_brid.jpg ther is a fish\n",
            "[[0.99997234]]\n",
            "f12_Wolf8.jpg ther is a fish\n",
            "[[0.]]\n",
            "f13_notfish.jpg ther is no fish\n",
            "[[2.1320388e-06]]\n",
            "f14_dog.jpg ther is no fish\n",
            "[[0.]]\n",
            "f15_dog2.jpg ther is no fish\n",
            "[[0.]]\n",
            "f16_notfish.jpg ther is no fish\n",
            "[[0.]]\n",
            "f17_dog3.jpg ther is no fish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCdk0whLJN1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('/content/data/weights_ImgNet_init.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}